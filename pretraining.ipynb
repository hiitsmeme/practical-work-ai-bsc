{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import roc_auc_score, auc, precision_recall_curve \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./data/data_scaled.npz')\n",
    "X_train = data['X_train']\n",
    "y_train = data['y_train']\n",
    "X_val = data['X_val']\n",
    "y_val = data[\"y_val\"]\n",
    "X_test = data['X_test']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout_rates=[0.5,0.25]):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.fc3 = nn.Linear(hidden_sizes[1], output_size)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.input_dropout = nn.Dropout(dropout_rates[0])\n",
    "        self.hidden_dropout = nn.Dropout(dropout_rates[1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_dropout(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.hidden_dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrAucIndividualClass(train_or_val, all_labels, all_preds, writer, epoch):\n",
    "    # stack label arrays vertically\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    # convert them to torch, for gpu compatibility\n",
    "    all_labels = torch.tensor(all_labels)\n",
    "    all_preds = torch.tensor(all_preds)\n",
    "    all_pr_auc = []\n",
    "    all_roc_auc = []\n",
    "    # loop over 9 tasks\n",
    "    for class_idx in range(all_labels.shape[1]):\n",
    "        mask = ~torch.isnan(all_labels[:, class_idx])   # mask out NaN values\n",
    "        class_labels = all_labels[:,class_idx][mask]    # get labels for current class\n",
    "        class_preds = all_preds[:,class_idx][mask]      # get model preds for current class\n",
    "        roc_auc = roc_auc_score(class_labels, class_preds)\n",
    "        baseline = class_labels.mean()   # baseline is portion of pos labels  \n",
    "        precision, recall, _ = precision_recall_curve(class_labels, class_preds)\n",
    "        pr_auc = auc(recall, precision) - baseline # computes delta auc-pr\n",
    "        all_pr_auc.append(pr_auc)\n",
    "        all_roc_auc.append(roc_auc)\n",
    "\n",
    "        # used for logging to tensorboard\n",
    "        # writer.add_pr_curve(f\"{train_or_val} Precision-Recall Class {class_idx}\", class_labels, class_preds, epoch)\n",
    "        # writer.add_scalar(f\"{train_or_val} PR-AUC Delta Class {class_idx}\", pr_auc, epoch)\n",
    "        # writer.add_scalar(f\"{train_or_val} ROC-AUC Class {class_idx}\", roc_auc, epoch)\n",
    "        \n",
    "    # return metrics averaged over tasks and not averaged over tasks\n",
    "    return np.mean(np.array(all_pr_auc)), np.mean(np.array(all_roc_auc)), np.array(all_pr_auc), np.array(all_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weighted_loss(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Compute batch-wise weighted loss, giving equal influence to all targets.\n",
    "    \"\"\"\n",
    "    # Create a mask for valid labels (non-NaN)\n",
    "    mask = ~torch.isnan(y_true)  # True where valid\n",
    "\n",
    "    # Count valid labels per target in the batch\n",
    "    target_counts = mask.sum(dim=0)  # Number of valid samples per target in this batch\n",
    "    # Avoid division by zero (replace 0 counts with 1)\n",
    "    target_counts = target_counts.float().clamp(min=1)\n",
    "\n",
    "    # Compute target-wise weights (Inverse of label frequency)\n",
    "    target_weights = target_counts.max() / target_counts  # Higher weight for rare labels\n",
    "    # Compute loss (Binary Cross-Entropy)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(reduction='none')\n",
    "    loss = criterion(y_pred, torch.nan_to_num(y_true, nan=0.0))  # Replace NaNs with 0 for loss computation\n",
    "\n",
    "    # Apply target-wise weights (broadcasting)\n",
    "    weighted_loss = loss * target_weights\n",
    "\n",
    "    # Compute final loss (only averaging over valid elements)\n",
    "    final_loss = torch.nanmean(weighted_loss)  # Ignore NaNs in loss calculation\n",
    "    return final_loss\n",
    "\n",
    "# not used\n",
    "def masked_bce_loss(outputs, targets):\n",
    "    mask = ~torch.isnan(targets)  # Create a mask where values are NOT NaN\n",
    "    loss = nn.functional.binary_cross_entropy_with_logits(outputs[mask], targets[mask])  # Compute loss only on valid labels\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_model(model, avg_pr_auc, best_score, file_path):\n",
    "    # Check if the current average PR AUC is better than the best recorded score\n",
    "    if avg_pr_auc > best_score:\n",
    "        torch.save(model.state_dict(), file_path)\n",
    "        print(f\"Saved new best model with avg PR AUC: {avg_pr_auc:.4f}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Current avg PR AUC: {avg_pr_auc:.4f} did not improve over best score: {best_score:.4f}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, writer, num_epochs=10):\n",
    "    model.to(device)\n",
    "    best_score = 0\n",
    "    file_path = \"best_model.pth\"\n",
    "    for epoch in range(num_epochs):\n",
    "        # ------------- TRAINING ------------ #\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_labels_train = []\n",
    "        all_preds_train = []\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.view(inputs.size(0), -1).to(device), labels.to(device)  # load inputs & labels onto gpu\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)  # criterion is loss fct passed to function, NaN values are masked there\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Store predictions & labels for AUC-PR computation\n",
    "            all_labels_train.append(labels.detach().cpu().numpy())\n",
    "            all_preds_train.append(torch.sigmoid(outputs).detach().cpu().numpy())  # Convert logits to probabilities\n",
    "\n",
    "        # Compute training AUC-PR\n",
    "        train_pr_auc, train_roc_auc, _, _ = getPrAucIndividualClass(\"Train\", all_labels_train, all_preds_train, writer, epoch)\n",
    "        epoch_loss_train = running_loss / len(train_loader)\n",
    "\n",
    "        # log loss and auc-pr to tensorboard\n",
    "        # writer.add_scalar(\"Loss/Training\", epoch_loss_train, epoch)\n",
    "\n",
    "        # --------- EVALUATION AFTER EPOCH --------------- #\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_labels_val = []\n",
    "        all_preds_val = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device) # load to gpu\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Store predictions & labels for AUC-PR computation\n",
    "                all_labels_val.append(labels.cpu().numpy())\n",
    "                all_preds_val.append(torch.sigmoid(outputs).cpu().numpy())  # Convert logits to probabilities\n",
    "\n",
    "        epoch_loss_val = val_loss / len(val_loader)\n",
    "\n",
    "        # log to tensorboard\n",
    "        # writer.add_scalar(\"Loss/Validation\", epoch_loss_val, epoch)\n",
    "\n",
    "        # Compute Validation metrics\n",
    "        val_pr_auc, val_roc_auc, _, _ = getPrAucIndividualClass(\"Val\", all_labels_val, all_preds_val, writer, epoch)\n",
    "        # if better, store model\n",
    "        saved = save_best_model(model, avg_pr_auc=val_pr_auc, best_score=best_score, file_path=file_path)\n",
    "        if saved:\n",
    "            best_score = val_pr_auc\n",
    "\n",
    "        # ------------------- END of EPOCH STUFF ------------- #\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "              f\"Train Loss: {epoch_loss_train:.4f}, Avg Train AUC-PR: {train_pr_auc:.4f}, Avg Train AUC-ROC: {train_roc_auc:.4f} | \"\n",
    "              f\"Val Loss: {epoch_loss_val:.4f}, Avg Val AUC-PR: {val_pr_auc:.4f}, Avg Val AUC-ROC: {val_roc_auc:.4f}\"\n",
    "        )\n",
    "        \n",
    "        # Log model parameters and gradients to tensorboard\n",
    "        # for name, param in model.named_parameters():\n",
    "        #     writer.add_histogram(name, param, epoch)\n",
    "        #     writer.add_histogram(f\"{name}.grad\", param.grad, epoch)\n",
    "        # log model architecture to tensorboard\n",
    "        # writer.add_graph(model, torch.randn(1, 2248).to(device))\n",
    "    \n",
    "    # ----------- EVALUATE BEST MODEL ------------- #\n",
    "    model.load_state_dict(torch.load(file_path, map_location=device)) # load best model\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_labels_val = []\n",
    "    all_preds_val = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # load input & labels onto gpu\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Store predictions & labels for AUC-PR computation\n",
    "            all_labels_val.append(labels.cpu().numpy())\n",
    "            all_preds_val.append(torch.sigmoid(outputs).cpu().numpy())  # Convert logits to probabilities\n",
    "\n",
    "    epoch_loss_val = val_loss / len(val_loader)\n",
    "    #writer.add_scalar(\"Loss/Validation\", epoch_loss_val, epoch) # tensorboard\n",
    "\n",
    "    # Compute metrics for best model and return them\n",
    "    val_pr_auc, val_roc_auc, val_pr_auc_per_task, val_roc_auc_per_task = getPrAucIndividualClass(\"Best Val\", all_labels_val, all_preds_val, writer, epoch)\n",
    "    print(f\"Best Model Results | \"\n",
    "              f\"Avg Val AUC-PR: {val_pr_auc:.4f}, Avg Val AUC-ROC: {val_roc_auc:.4f}\"\n",
    "        )\n",
    "    return epoch_loss_val, val_pr_auc, val_roc_auc, val_pr_auc_per_task, val_roc_auc_per_task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creae dataloaders\n",
    "def get_datasets(X_train, y_train, X_val, y_val, X_test, y_test, seed):\n",
    "    def worker_init_fn(worker_id):\n",
    "        # Adjust the seed based on the worker id to ensure different seeds for each worker.\n",
    "        np.random.seed(seed + worker_id)\n",
    "        random.seed(seed + worker_id)\n",
    "\n",
    "    batch_size = 120\n",
    "    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,worker_init_fn=worker_init_fn)\n",
    "\n",
    "    val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32))\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True,worker_init_fn=worker_init_fn)\n",
    "\n",
    "    test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, worker_init_fn=worker_init_fn)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Saved new best model with avg PR AUC: 0.0391\n",
      "Epoch 1/20 | Train Loss: 0.0446, Avg Train AUC-PR: 0.0008, Avg Train AUC-ROC: 0.5493 | Val Loss: 0.0059, Avg Val AUC-PR: 0.0391, Avg Val AUC-ROC: 0.6500\n",
      "Saved new best model with avg PR AUC: 0.0513\n",
      "Epoch 2/20 | Train Loss: 0.0037, Avg Train AUC-PR: 0.0142, Avg Train AUC-ROC: 0.7350 | Val Loss: 0.0057, Avg Val AUC-PR: 0.0513, Avg Val AUC-ROC: 0.7398\n",
      "Current avg PR AUC: 0.0294 did not improve over best score: 0.0513\n",
      "Epoch 3/20 | Train Loss: 0.0031, Avg Train AUC-PR: 0.0205, Avg Train AUC-ROC: 0.8637 | Val Loss: 0.0053, Avg Val AUC-PR: 0.0294, Avg Val AUC-ROC: 0.7145\n",
      "Current avg PR AUC: 0.0149 did not improve over best score: 0.0513\n",
      "Epoch 4/20 | Train Loss: 0.0030, Avg Train AUC-PR: 0.0392, Avg Train AUC-ROC: 0.8886 | Val Loss: 0.0060, Avg Val AUC-PR: 0.0149, Avg Val AUC-ROC: 0.6683\n",
      "Current avg PR AUC: 0.0284 did not improve over best score: 0.0513\n",
      "Epoch 5/20 | Train Loss: 0.0030, Avg Train AUC-PR: 0.0681, Avg Train AUC-ROC: 0.9007 | Val Loss: 0.0063, Avg Val AUC-PR: 0.0284, Avg Val AUC-ROC: 0.6675\n",
      "Current avg PR AUC: 0.0189 did not improve over best score: 0.0513\n",
      "Epoch 6/20 | Train Loss: 0.0026, Avg Train AUC-PR: 0.1187, Avg Train AUC-ROC: 0.9406 | Val Loss: 0.0068, Avg Val AUC-PR: 0.0189, Avg Val AUC-ROC: 0.6690\n",
      "Current avg PR AUC: 0.0228 did not improve over best score: 0.0513\n",
      "Epoch 7/20 | Train Loss: 0.0025, Avg Train AUC-PR: 0.1110, Avg Train AUC-ROC: 0.9597 | Val Loss: 0.0074, Avg Val AUC-PR: 0.0228, Avg Val AUC-ROC: 0.6670\n",
      "Current avg PR AUC: 0.0489 did not improve over best score: 0.0513\n",
      "Epoch 8/20 | Train Loss: 0.0023, Avg Train AUC-PR: 0.1610, Avg Train AUC-ROC: 0.9707 | Val Loss: 0.0065, Avg Val AUC-PR: 0.0489, Avg Val AUC-ROC: 0.6775\n",
      "Saved new best model with avg PR AUC: 0.0628\n",
      "Epoch 9/20 | Train Loss: 0.0022, Avg Train AUC-PR: 0.2897, Avg Train AUC-ROC: 0.9700 | Val Loss: 0.0071, Avg Val AUC-PR: 0.0628, Avg Val AUC-ROC: 0.6829\n",
      "Current avg PR AUC: 0.0539 did not improve over best score: 0.0628\n",
      "Epoch 10/20 | Train Loss: 0.0019, Avg Train AUC-PR: 0.3692, Avg Train AUC-ROC: 0.9835 | Val Loss: 0.0076, Avg Val AUC-PR: 0.0539, Avg Val AUC-ROC: 0.6943\n",
      "Current avg PR AUC: 0.0537 did not improve over best score: 0.0628\n",
      "Epoch 11/20 | Train Loss: 0.0018, Avg Train AUC-PR: 0.3934, Avg Train AUC-ROC: 0.9884 | Val Loss: 0.0090, Avg Val AUC-PR: 0.0537, Avg Val AUC-ROC: 0.6915\n",
      "Current avg PR AUC: 0.0543 did not improve over best score: 0.0628\n",
      "Epoch 12/20 | Train Loss: 0.0019, Avg Train AUC-PR: 0.4355, Avg Train AUC-ROC: 0.9807 | Val Loss: 0.0085, Avg Val AUC-PR: 0.0543, Avg Val AUC-ROC: 0.6938\n",
      "Current avg PR AUC: 0.0541 did not improve over best score: 0.0628\n",
      "Epoch 13/20 | Train Loss: 0.0016, Avg Train AUC-PR: 0.4825, Avg Train AUC-ROC: 0.9917 | Val Loss: 0.0099, Avg Val AUC-PR: 0.0541, Avg Val AUC-ROC: 0.6998\n",
      "Saved new best model with avg PR AUC: 0.0702\n",
      "Epoch 14/20 | Train Loss: 0.0015, Avg Train AUC-PR: 0.5465, Avg Train AUC-ROC: 0.9918 | Val Loss: 0.0105, Avg Val AUC-PR: 0.0702, Avg Val AUC-ROC: 0.6787\n",
      "Current avg PR AUC: 0.0443 did not improve over best score: 0.0702\n",
      "Epoch 15/20 | Train Loss: 0.0014, Avg Train AUC-PR: 0.5822, Avg Train AUC-ROC: 0.9922 | Val Loss: 0.0102, Avg Val AUC-PR: 0.0443, Avg Val AUC-ROC: 0.6841\n",
      "Current avg PR AUC: 0.0562 did not improve over best score: 0.0702\n",
      "Epoch 16/20 | Train Loss: 0.0016, Avg Train AUC-PR: 0.5817, Avg Train AUC-ROC: 0.9818 | Val Loss: 0.0112, Avg Val AUC-PR: 0.0562, Avg Val AUC-ROC: 0.6112\n",
      "Current avg PR AUC: 0.0678 did not improve over best score: 0.0702\n",
      "Epoch 17/20 | Train Loss: 0.0015, Avg Train AUC-PR: 0.5829, Avg Train AUC-ROC: 0.9899 | Val Loss: 0.0117, Avg Val AUC-PR: 0.0678, Avg Val AUC-ROC: 0.6289\n",
      "Current avg PR AUC: 0.0662 did not improve over best score: 0.0702\n",
      "Epoch 18/20 | Train Loss: 0.0012, Avg Train AUC-PR: 0.7228, Avg Train AUC-ROC: 0.9958 | Val Loss: 0.0132, Avg Val AUC-PR: 0.0662, Avg Val AUC-ROC: 0.6034\n",
      "Current avg PR AUC: 0.0633 did not improve over best score: 0.0702\n",
      "Epoch 19/20 | Train Loss: 0.0013, Avg Train AUC-PR: 0.6683, Avg Train AUC-ROC: 0.9943 | Val Loss: 0.0134, Avg Val AUC-PR: 0.0633, Avg Val AUC-ROC: 0.5989\n",
      "Saved new best model with avg PR AUC: 0.0704\n",
      "Epoch 20/20 | Train Loss: 0.0014, Avg Train AUC-PR: 0.6378, Avg Train AUC-ROC: 0.9932 | Val Loss: 0.0130, Avg Val AUC-PR: 0.0704, Avg Val AUC-ROC: 0.6244\n",
      "Best Model Results | Avg Val AUC-PR: 0.0704, Avg Val AUC-ROC: 0.6244\n",
      "cuda\n",
      "Saved new best model with avg PR AUC: 0.0356\n",
      "Epoch 1/20 | Train Loss: 0.0432, Avg Train AUC-PR: 0.0012, Avg Train AUC-ROC: 0.5941 | Val Loss: 0.0057, Avg Val AUC-PR: 0.0356, Avg Val AUC-ROC: 0.6609\n",
      "Current avg PR AUC: 0.0142 did not improve over best score: 0.0356\n",
      "Epoch 2/20 | Train Loss: 0.0034, Avg Train AUC-PR: 0.0292, Avg Train AUC-ROC: 0.7840 | Val Loss: 0.0054, Avg Val AUC-PR: 0.0142, Avg Val AUC-ROC: 0.7133\n",
      "Current avg PR AUC: 0.0330 did not improve over best score: 0.0356\n",
      "Epoch 3/20 | Train Loss: 0.0033, Avg Train AUC-PR: 0.0227, Avg Train AUC-ROC: 0.8449 | Val Loss: 0.0056, Avg Val AUC-PR: 0.0330, Avg Val AUC-ROC: 0.6818\n",
      "Saved new best model with avg PR AUC: 0.0539\n",
      "Epoch 4/20 | Train Loss: 0.0030, Avg Train AUC-PR: 0.0492, Avg Train AUC-ROC: 0.8790 | Val Loss: 0.0057, Avg Val AUC-PR: 0.0539, Avg Val AUC-ROC: 0.7198\n",
      "Current avg PR AUC: 0.0281 did not improve over best score: 0.0539\n",
      "Epoch 5/20 | Train Loss: 0.0029, Avg Train AUC-PR: 0.0423, Avg Train AUC-ROC: 0.9049 | Val Loss: 0.0060, Avg Val AUC-PR: 0.0281, Avg Val AUC-ROC: 0.7182\n",
      "Saved new best model with avg PR AUC: 0.1066\n",
      "Epoch 6/20 | Train Loss: 0.0027, Avg Train AUC-PR: 0.0972, Avg Train AUC-ROC: 0.9287 | Val Loss: 0.0055, Avg Val AUC-PR: 0.1066, Avg Val AUC-ROC: 0.7271\n",
      "Current avg PR AUC: 0.0808 did not improve over best score: 0.1066\n",
      "Epoch 7/20 | Train Loss: 0.0024, Avg Train AUC-PR: 0.1303, Avg Train AUC-ROC: 0.9563 | Val Loss: 0.0052, Avg Val AUC-PR: 0.0808, Avg Val AUC-ROC: 0.7301\n",
      "Saved new best model with avg PR AUC: 0.1459\n",
      "Epoch 8/20 | Train Loss: 0.0022, Avg Train AUC-PR: 0.2231, Avg Train AUC-ROC: 0.9683 | Val Loss: 0.0062, Avg Val AUC-PR: 0.1459, Avg Val AUC-ROC: 0.7013\n",
      "Current avg PR AUC: 0.0887 did not improve over best score: 0.1459\n",
      "Epoch 9/20 | Train Loss: 0.0022, Avg Train AUC-PR: 0.2758, Avg Train AUC-ROC: 0.9677 | Val Loss: 0.0080, Avg Val AUC-PR: 0.0887, Avg Val AUC-ROC: 0.6624\n",
      "Saved new best model with avg PR AUC: 0.1520\n",
      "Epoch 10/20 | Train Loss: 0.0021, Avg Train AUC-PR: 0.2871, Avg Train AUC-ROC: 0.9834 | Val Loss: 0.0076, Avg Val AUC-PR: 0.1520, Avg Val AUC-ROC: 0.6283\n",
      "Current avg PR AUC: 0.0920 did not improve over best score: 0.1520\n",
      "Epoch 11/20 | Train Loss: 0.0018, Avg Train AUC-PR: 0.3980, Avg Train AUC-ROC: 0.9810 | Val Loss: 0.0084, Avg Val AUC-PR: 0.0920, Avg Val AUC-ROC: 0.6183\n",
      "Current avg PR AUC: 0.0776 did not improve over best score: 0.1520\n",
      "Epoch 12/20 | Train Loss: 0.0017, Avg Train AUC-PR: 0.4585, Avg Train AUC-ROC: 0.9905 | Val Loss: 0.0091, Avg Val AUC-PR: 0.0776, Avg Val AUC-ROC: 0.6317\n",
      "Current avg PR AUC: 0.0749 did not improve over best score: 0.1520\n",
      "Epoch 13/20 | Train Loss: 0.0016, Avg Train AUC-PR: 0.4997, Avg Train AUC-ROC: 0.9890 | Val Loss: 0.0099, Avg Val AUC-PR: 0.0749, Avg Val AUC-ROC: 0.6316\n",
      "Current avg PR AUC: 0.0694 did not improve over best score: 0.1520\n",
      "Epoch 14/20 | Train Loss: 0.0015, Avg Train AUC-PR: 0.5100, Avg Train AUC-ROC: 0.9926 | Val Loss: 0.0095, Avg Val AUC-PR: 0.0694, Avg Val AUC-ROC: 0.6460\n",
      "Current avg PR AUC: 0.0427 did not improve over best score: 0.1520\n",
      "Epoch 15/20 | Train Loss: 0.0016, Avg Train AUC-PR: 0.5292, Avg Train AUC-ROC: 0.9932 | Val Loss: 0.0104, Avg Val AUC-PR: 0.0427, Avg Val AUC-ROC: 0.6316\n",
      "Current avg PR AUC: 0.0604 did not improve over best score: 0.1520\n",
      "Epoch 16/20 | Train Loss: 0.0013, Avg Train AUC-PR: 0.6422, Avg Train AUC-ROC: 0.9957 | Val Loss: 0.0129, Avg Val AUC-PR: 0.0604, Avg Val AUC-ROC: 0.6281\n",
      "Current avg PR AUC: 0.0693 did not improve over best score: 0.1520\n",
      "Epoch 17/20 | Train Loss: 0.0012, Avg Train AUC-PR: 0.6481, Avg Train AUC-ROC: 0.9949 | Val Loss: 0.0119, Avg Val AUC-PR: 0.0693, Avg Val AUC-ROC: 0.6306\n",
      "Current avg PR AUC: 0.0323 did not improve over best score: 0.1520\n",
      "Epoch 18/20 | Train Loss: 0.0013, Avg Train AUC-PR: 0.6663, Avg Train AUC-ROC: 0.9941 | Val Loss: 0.0134, Avg Val AUC-PR: 0.0323, Avg Val AUC-ROC: 0.6359\n",
      "Current avg PR AUC: 0.0593 did not improve over best score: 0.1520\n",
      "Epoch 19/20 | Train Loss: 0.0014, Avg Train AUC-PR: 0.6218, Avg Train AUC-ROC: 0.9923 | Val Loss: 0.0123, Avg Val AUC-PR: 0.0593, Avg Val AUC-ROC: 0.6325\n",
      "Current avg PR AUC: 0.0964 did not improve over best score: 0.1520\n",
      "Epoch 20/20 | Train Loss: 0.0013, Avg Train AUC-PR: 0.6627, Avg Train AUC-ROC: 0.9890 | Val Loss: 0.0138, Avg Val AUC-PR: 0.0964, Avg Val AUC-ROC: 0.6196\n",
      "Best Model Results | Avg Val AUC-PR: 0.1520, Avg Val AUC-ROC: 0.6283\n",
      "cuda\n",
      "Saved new best model with avg PR AUC: 0.0430\n",
      "Epoch 1/20 | Train Loss: 0.0504, Avg Train AUC-PR: 0.0015, Avg Train AUC-ROC: 0.5605 | Val Loss: 0.0057, Avg Val AUC-PR: 0.0430, Avg Val AUC-ROC: 0.6835\n",
      "Current avg PR AUC: 0.0410 did not improve over best score: 0.0430\n",
      "Epoch 2/20 | Train Loss: 0.0036, Avg Train AUC-PR: 0.0216, Avg Train AUC-ROC: 0.7740 | Val Loss: 0.0056, Avg Val AUC-PR: 0.0410, Avg Val AUC-ROC: 0.7104\n",
      "Saved new best model with avg PR AUC: 0.0533\n",
      "Epoch 3/20 | Train Loss: 0.0032, Avg Train AUC-PR: 0.0192, Avg Train AUC-ROC: 0.8683 | Val Loss: 0.0059, Avg Val AUC-PR: 0.0533, Avg Val AUC-ROC: 0.6920\n",
      "Current avg PR AUC: 0.0281 did not improve over best score: 0.0533\n",
      "Epoch 4/20 | Train Loss: 0.0031, Avg Train AUC-PR: 0.0421, Avg Train AUC-ROC: 0.8775 | Val Loss: 0.0061, Avg Val AUC-PR: 0.0281, Avg Val AUC-ROC: 0.7273\n",
      "Current avg PR AUC: 0.0219 did not improve over best score: 0.0533\n",
      "Epoch 5/20 | Train Loss: 0.0028, Avg Train AUC-PR: 0.0812, Avg Train AUC-ROC: 0.9171 | Val Loss: 0.0066, Avg Val AUC-PR: 0.0219, Avg Val AUC-ROC: 0.7091\n",
      "Current avg PR AUC: 0.0210 did not improve over best score: 0.0533\n",
      "Epoch 6/20 | Train Loss: 0.0026, Avg Train AUC-PR: 0.1197, Avg Train AUC-ROC: 0.9406 | Val Loss: 0.0062, Avg Val AUC-PR: 0.0210, Avg Val AUC-ROC: 0.7048\n",
      "Current avg PR AUC: 0.0499 did not improve over best score: 0.0533\n",
      "Epoch 7/20 | Train Loss: 0.0026, Avg Train AUC-PR: 0.1149, Avg Train AUC-ROC: 0.9544 | Val Loss: 0.0066, Avg Val AUC-PR: 0.0499, Avg Val AUC-ROC: 0.7043\n",
      "Saved new best model with avg PR AUC: 0.0860\n",
      "Epoch 8/20 | Train Loss: 0.0023, Avg Train AUC-PR: 0.2003, Avg Train AUC-ROC: 0.9677 | Val Loss: 0.0067, Avg Val AUC-PR: 0.0860, Avg Val AUC-ROC: 0.7264\n",
      "Current avg PR AUC: 0.0491 did not improve over best score: 0.0860\n",
      "Epoch 9/20 | Train Loss: 0.0022, Avg Train AUC-PR: 0.2808, Avg Train AUC-ROC: 0.9727 | Val Loss: 0.0078, Avg Val AUC-PR: 0.0491, Avg Val AUC-ROC: 0.7075\n",
      "Current avg PR AUC: 0.0673 did not improve over best score: 0.0860\n",
      "Epoch 10/20 | Train Loss: 0.0019, Avg Train AUC-PR: 0.3409, Avg Train AUC-ROC: 0.9819 | Val Loss: 0.0076, Avg Val AUC-PR: 0.0673, Avg Val AUC-ROC: 0.6868\n",
      "Current avg PR AUC: 0.0722 did not improve over best score: 0.0860\n",
      "Epoch 11/20 | Train Loss: 0.0018, Avg Train AUC-PR: 0.4686, Avg Train AUC-ROC: 0.9845 | Val Loss: 0.0080, Avg Val AUC-PR: 0.0722, Avg Val AUC-ROC: 0.7008\n",
      "Current avg PR AUC: 0.0715 did not improve over best score: 0.0860\n",
      "Epoch 12/20 | Train Loss: 0.0018, Avg Train AUC-PR: 0.4653, Avg Train AUC-ROC: 0.9794 | Val Loss: 0.0080, Avg Val AUC-PR: 0.0715, Avg Val AUC-ROC: 0.6948\n",
      "Current avg PR AUC: 0.0297 did not improve over best score: 0.0860\n",
      "Epoch 13/20 | Train Loss: 0.0016, Avg Train AUC-PR: 0.5296, Avg Train AUC-ROC: 0.9918 | Val Loss: 0.0088, Avg Val AUC-PR: 0.0297, Avg Val AUC-ROC: 0.6883\n",
      "Current avg PR AUC: 0.0751 did not improve over best score: 0.0860\n",
      "Epoch 14/20 | Train Loss: 0.0016, Avg Train AUC-PR: 0.5133, Avg Train AUC-ROC: 0.9915 | Val Loss: 0.0090, Avg Val AUC-PR: 0.0751, Avg Val AUC-ROC: 0.7122\n",
      "Current avg PR AUC: 0.0556 did not improve over best score: 0.0860\n",
      "Epoch 15/20 | Train Loss: 0.0015, Avg Train AUC-PR: 0.5711, Avg Train AUC-ROC: 0.9922 | Val Loss: 0.0101, Avg Val AUC-PR: 0.0556, Avg Val AUC-ROC: 0.6771\n",
      "Current avg PR AUC: 0.0639 did not improve over best score: 0.0860\n",
      "Epoch 16/20 | Train Loss: 0.0013, Avg Train AUC-PR: 0.6560, Avg Train AUC-ROC: 0.9925 | Val Loss: 0.0101, Avg Val AUC-PR: 0.0639, Avg Val AUC-ROC: 0.6779\n",
      "Current avg PR AUC: 0.0401 did not improve over best score: 0.0860\n",
      "Epoch 17/20 | Train Loss: 0.0013, Avg Train AUC-PR: 0.6742, Avg Train AUC-ROC: 0.9970 | Val Loss: 0.0106, Avg Val AUC-PR: 0.0401, Avg Val AUC-ROC: 0.6657\n",
      "Current avg PR AUC: 0.0605 did not improve over best score: 0.0860\n",
      "Epoch 18/20 | Train Loss: 0.0013, Avg Train AUC-PR: 0.6833, Avg Train AUC-ROC: 0.9930 | Val Loss: 0.0104, Avg Val AUC-PR: 0.0605, Avg Val AUC-ROC: 0.6795\n",
      "Current avg PR AUC: 0.0462 did not improve over best score: 0.0860\n",
      "Epoch 19/20 | Train Loss: 0.0011, Avg Train AUC-PR: 0.7372, Avg Train AUC-ROC: 0.9950 | Val Loss: 0.0121, Avg Val AUC-PR: 0.0462, Avg Val AUC-ROC: 0.6579\n",
      "Current avg PR AUC: 0.0715 did not improve over best score: 0.0860\n",
      "Epoch 20/20 | Train Loss: 0.0012, Avg Train AUC-PR: 0.7075, Avg Train AUC-ROC: 0.9944 | Val Loss: 0.0121, Avg Val AUC-PR: 0.0715, Avg Val AUC-ROC: 0.6400\n",
      "Best Model Results | Avg Val AUC-PR: 0.0860, Avg Val AUC-ROC: 0.7264\n",
      "cuda\n",
      "Saved new best model with avg PR AUC: 0.0338\n",
      "Epoch 1/20 | Train Loss: 0.0504, Avg Train AUC-PR: 0.0010, Avg Train AUC-ROC: 0.5644 | Val Loss: 0.0059, Avg Val AUC-PR: 0.0338, Avg Val AUC-ROC: 0.6023\n",
      "Current avg PR AUC: 0.0269 did not improve over best score: 0.0338\n",
      "Epoch 2/20 | Train Loss: 0.0036, Avg Train AUC-PR: 0.0089, Avg Train AUC-ROC: 0.7691 | Val Loss: 0.0057, Avg Val AUC-PR: 0.0269, Avg Val AUC-ROC: 0.6959\n",
      "Saved new best model with avg PR AUC: 0.0449\n",
      "Epoch 3/20 | Train Loss: 0.0032, Avg Train AUC-PR: 0.0214, Avg Train AUC-ROC: 0.8672 | Val Loss: 0.0056, Avg Val AUC-PR: 0.0449, Avg Val AUC-ROC: 0.7151\n",
      "Current avg PR AUC: 0.0136 did not improve over best score: 0.0449\n",
      "Epoch 4/20 | Train Loss: 0.0031, Avg Train AUC-PR: 0.0340, Avg Train AUC-ROC: 0.8931 | Val Loss: 0.0055, Avg Val AUC-PR: 0.0136, Avg Val AUC-ROC: 0.7007\n",
      "Current avg PR AUC: 0.0270 did not improve over best score: 0.0449\n",
      "Epoch 5/20 | Train Loss: 0.0029, Avg Train AUC-PR: 0.0778, Avg Train AUC-ROC: 0.8985 | Val Loss: 0.0064, Avg Val AUC-PR: 0.0270, Avg Val AUC-ROC: 0.7085\n",
      "Saved new best model with avg PR AUC: 0.0801\n",
      "Epoch 6/20 | Train Loss: 0.0026, Avg Train AUC-PR: 0.0875, Avg Train AUC-ROC: 0.9471 | Val Loss: 0.0056, Avg Val AUC-PR: 0.0801, Avg Val AUC-ROC: 0.6888\n",
      "Saved new best model with avg PR AUC: 0.0893\n",
      "Epoch 7/20 | Train Loss: 0.0025, Avg Train AUC-PR: 0.1655, Avg Train AUC-ROC: 0.9551 | Val Loss: 0.0068, Avg Val AUC-PR: 0.0893, Avg Val AUC-ROC: 0.6956\n",
      "Current avg PR AUC: 0.0783 did not improve over best score: 0.0893\n",
      "Epoch 8/20 | Train Loss: 0.0024, Avg Train AUC-PR: 0.1879, Avg Train AUC-ROC: 0.9644 | Val Loss: 0.0075, Avg Val AUC-PR: 0.0783, Avg Val AUC-ROC: 0.6773\n",
      "Current avg PR AUC: 0.0745 did not improve over best score: 0.0893\n",
      "Epoch 9/20 | Train Loss: 0.0022, Avg Train AUC-PR: 0.2195, Avg Train AUC-ROC: 0.9650 | Val Loss: 0.0072, Avg Val AUC-PR: 0.0745, Avg Val AUC-ROC: 0.6920\n",
      "Saved new best model with avg PR AUC: 0.0929\n",
      "Epoch 10/20 | Train Loss: 0.0019, Avg Train AUC-PR: 0.3242, Avg Train AUC-ROC: 0.9859 | Val Loss: 0.0073, Avg Val AUC-PR: 0.0929, Avg Val AUC-ROC: 0.7006\n",
      "Current avg PR AUC: 0.0722 did not improve over best score: 0.0929\n",
      "Epoch 11/20 | Train Loss: 0.0019, Avg Train AUC-PR: 0.3582, Avg Train AUC-ROC: 0.9857 | Val Loss: 0.0084, Avg Val AUC-PR: 0.0722, Avg Val AUC-ROC: 0.6517\n",
      "Saved new best model with avg PR AUC: 0.1255\n",
      "Epoch 12/20 | Train Loss: 0.0017, Avg Train AUC-PR: 0.4527, Avg Train AUC-ROC: 0.9853 | Val Loss: 0.0097, Avg Val AUC-PR: 0.1255, Avg Val AUC-ROC: 0.6958\n",
      "Current avg PR AUC: 0.0600 did not improve over best score: 0.1255\n",
      "Epoch 13/20 | Train Loss: 0.0016, Avg Train AUC-PR: 0.5075, Avg Train AUC-ROC: 0.9891 | Val Loss: 0.0093, Avg Val AUC-PR: 0.0600, Avg Val AUC-ROC: 0.7159\n",
      "Current avg PR AUC: 0.0561 did not improve over best score: 0.1255\n",
      "Epoch 14/20 | Train Loss: 0.0015, Avg Train AUC-PR: 0.5681, Avg Train AUC-ROC: 0.9929 | Val Loss: 0.0110, Avg Val AUC-PR: 0.0561, Avg Val AUC-ROC: 0.6657\n",
      "Current avg PR AUC: 0.0838 did not improve over best score: 0.1255\n",
      "Epoch 15/20 | Train Loss: 0.0015, Avg Train AUC-PR: 0.5758, Avg Train AUC-ROC: 0.9941 | Val Loss: 0.0116, Avg Val AUC-PR: 0.0838, Avg Val AUC-ROC: 0.6482\n",
      "Current avg PR AUC: 0.0773 did not improve over best score: 0.1255\n",
      "Epoch 16/20 | Train Loss: 0.0014, Avg Train AUC-PR: 0.5862, Avg Train AUC-ROC: 0.9946 | Val Loss: 0.0126, Avg Val AUC-PR: 0.0773, Avg Val AUC-ROC: 0.6531\n",
      "Current avg PR AUC: 0.0822 did not improve over best score: 0.1255\n",
      "Epoch 17/20 | Train Loss: 0.0013, Avg Train AUC-PR: 0.6685, Avg Train AUC-ROC: 0.9932 | Val Loss: 0.0128, Avg Val AUC-PR: 0.0822, Avg Val AUC-ROC: 0.6525\n",
      "Current avg PR AUC: 0.0729 did not improve over best score: 0.1255\n",
      "Epoch 18/20 | Train Loss: 0.0014, Avg Train AUC-PR: 0.6374, Avg Train AUC-ROC: 0.9932 | Val Loss: 0.0117, Avg Val AUC-PR: 0.0729, Avg Val AUC-ROC: 0.6410\n",
      "Current avg PR AUC: 0.0699 did not improve over best score: 0.1255\n",
      "Epoch 19/20 | Train Loss: 0.0010, Avg Train AUC-PR: 0.7667, Avg Train AUC-ROC: 0.9956 | Val Loss: 0.0135, Avg Val AUC-PR: 0.0699, Avg Val AUC-ROC: 0.6533\n",
      "Current avg PR AUC: 0.0808 did not improve over best score: 0.1255\n",
      "Epoch 20/20 | Train Loss: 0.0011, Avg Train AUC-PR: 0.7135, Avg Train AUC-ROC: 0.9964 | Val Loss: 0.0129, Avg Val AUC-PR: 0.0808, Avg Val AUC-ROC: 0.6456\n",
      "Best Model Results | Avg Val AUC-PR: 0.1255, Avg Val AUC-ROC: 0.6958\n",
      "cuda\n",
      "Saved new best model with avg PR AUC: 0.0325\n",
      "Epoch 1/20 | Train Loss: 0.0412, Avg Train AUC-PR: 0.0016, Avg Train AUC-ROC: 0.5495 | Val Loss: 0.0058, Avg Val AUC-PR: 0.0325, Avg Val AUC-ROC: 0.6490\n",
      "Saved new best model with avg PR AUC: 0.0446\n",
      "Epoch 2/20 | Train Loss: 0.0036, Avg Train AUC-PR: 0.0162, Avg Train AUC-ROC: 0.7548 | Val Loss: 0.0058, Avg Val AUC-PR: 0.0446, Avg Val AUC-ROC: 0.6228\n",
      "Current avg PR AUC: 0.0135 did not improve over best score: 0.0446\n",
      "Epoch 3/20 | Train Loss: 0.0031, Avg Train AUC-PR: 0.0337, Avg Train AUC-ROC: 0.8631 | Val Loss: 0.0060, Avg Val AUC-PR: 0.0135, Avg Val AUC-ROC: 0.6954\n",
      "Current avg PR AUC: 0.0382 did not improve over best score: 0.0446\n",
      "Epoch 4/20 | Train Loss: 0.0029, Avg Train AUC-PR: 0.0365, Avg Train AUC-ROC: 0.9089 | Val Loss: 0.0059, Avg Val AUC-PR: 0.0382, Avg Val AUC-ROC: 0.7249\n",
      "Current avg PR AUC: 0.0092 did not improve over best score: 0.0446\n",
      "Epoch 5/20 | Train Loss: 0.0030, Avg Train AUC-PR: 0.0576, Avg Train AUC-ROC: 0.9036 | Val Loss: 0.0061, Avg Val AUC-PR: 0.0092, Avg Val AUC-ROC: 0.7041\n",
      "Current avg PR AUC: 0.0441 did not improve over best score: 0.0446\n",
      "Epoch 6/20 | Train Loss: 0.0026, Avg Train AUC-PR: 0.0852, Avg Train AUC-ROC: 0.9386 | Val Loss: 0.0063, Avg Val AUC-PR: 0.0441, Avg Val AUC-ROC: 0.6928\n",
      "Saved new best model with avg PR AUC: 0.0502\n",
      "Epoch 7/20 | Train Loss: 0.0027, Avg Train AUC-PR: 0.0947, Avg Train AUC-ROC: 0.9444 | Val Loss: 0.0063, Avg Val AUC-PR: 0.0502, Avg Val AUC-ROC: 0.7163\n",
      "Saved new best model with avg PR AUC: 0.0507\n",
      "Epoch 8/20 | Train Loss: 0.0023, Avg Train AUC-PR: 0.1845, Avg Train AUC-ROC: 0.9669 | Val Loss: 0.0073, Avg Val AUC-PR: 0.0507, Avg Val AUC-ROC: 0.7057\n",
      "Saved new best model with avg PR AUC: 0.0526\n",
      "Epoch 9/20 | Train Loss: 0.0020, Avg Train AUC-PR: 0.2555, Avg Train AUC-ROC: 0.9800 | Val Loss: 0.0071, Avg Val AUC-PR: 0.0526, Avg Val AUC-ROC: 0.7053\n",
      "Current avg PR AUC: 0.0468 did not improve over best score: 0.0526\n",
      "Epoch 10/20 | Train Loss: 0.0021, Avg Train AUC-PR: 0.2515, Avg Train AUC-ROC: 0.9798 | Val Loss: 0.0074, Avg Val AUC-PR: 0.0468, Avg Val AUC-ROC: 0.6858\n",
      "Current avg PR AUC: 0.0309 did not improve over best score: 0.0526\n",
      "Epoch 11/20 | Train Loss: 0.0018, Avg Train AUC-PR: 0.4188, Avg Train AUC-ROC: 0.9864 | Val Loss: 0.0074, Avg Val AUC-PR: 0.0309, Avg Val AUC-ROC: 0.6947\n",
      "Current avg PR AUC: 0.0410 did not improve over best score: 0.0526\n",
      "Epoch 12/20 | Train Loss: 0.0017, Avg Train AUC-PR: 0.4801, Avg Train AUC-ROC: 0.9868 | Val Loss: 0.0090, Avg Val AUC-PR: 0.0410, Avg Val AUC-ROC: 0.6965\n",
      "Saved new best model with avg PR AUC: 0.0634\n",
      "Epoch 13/20 | Train Loss: 0.0017, Avg Train AUC-PR: 0.4860, Avg Train AUC-ROC: 0.9900 | Val Loss: 0.0092, Avg Val AUC-PR: 0.0634, Avg Val AUC-ROC: 0.6519\n",
      "Current avg PR AUC: 0.0303 did not improve over best score: 0.0634\n",
      "Epoch 14/20 | Train Loss: 0.0017, Avg Train AUC-PR: 0.4709, Avg Train AUC-ROC: 0.9939 | Val Loss: 0.0104, Avg Val AUC-PR: 0.0303, Avg Val AUC-ROC: 0.6716\n",
      "Current avg PR AUC: 0.0290 did not improve over best score: 0.0634\n",
      "Epoch 15/20 | Train Loss: 0.0013, Avg Train AUC-PR: 0.6479, Avg Train AUC-ROC: 0.9961 | Val Loss: 0.0107, Avg Val AUC-PR: 0.0290, Avg Val AUC-ROC: 0.7062\n",
      "Current avg PR AUC: 0.0345 did not improve over best score: 0.0634\n",
      "Epoch 16/20 | Train Loss: 0.0014, Avg Train AUC-PR: 0.5540, Avg Train AUC-ROC: 0.9947 | Val Loss: 0.0119, Avg Val AUC-PR: 0.0345, Avg Val AUC-ROC: 0.6751\n",
      "Current avg PR AUC: 0.0462 did not improve over best score: 0.0634\n",
      "Epoch 17/20 | Train Loss: 0.0013, Avg Train AUC-PR: 0.6590, Avg Train AUC-ROC: 0.9964 | Val Loss: 0.0114, Avg Val AUC-PR: 0.0462, Avg Val AUC-ROC: 0.6669\n",
      "Current avg PR AUC: 0.0465 did not improve over best score: 0.0634\n",
      "Epoch 18/20 | Train Loss: 0.0014, Avg Train AUC-PR: 0.6604, Avg Train AUC-ROC: 0.9929 | Val Loss: 0.0132, Avg Val AUC-PR: 0.0465, Avg Val AUC-ROC: 0.6444\n",
      "Current avg PR AUC: 0.0374 did not improve over best score: 0.0634\n",
      "Epoch 19/20 | Train Loss: 0.0013, Avg Train AUC-PR: 0.6628, Avg Train AUC-ROC: 0.9963 | Val Loss: 0.0138, Avg Val AUC-PR: 0.0374, Avg Val AUC-ROC: 0.6261\n",
      "Current avg PR AUC: 0.0384 did not improve over best score: 0.0634\n",
      "Epoch 20/20 | Train Loss: 0.0014, Avg Train AUC-PR: 0.6619, Avg Train AUC-ROC: 0.9939 | Val Loss: 0.0139, Avg Val AUC-PR: 0.0384, Avg Val AUC-ROC: 0.6218\n",
      "Best Model Results | Avg Val AUC-PR: 0.0634, Avg Val AUC-ROC: 0.6519\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters & global vars\n",
    "input_size = 2248 \n",
    "hidden_sizes = [120, 48, None]\n",
    "output_size = 9\n",
    "batch_size = 120\n",
    "lr = 0.001\n",
    "dropout_rates = [0.3, 0.5] # input dropout, hidden dropout\n",
    "seeds = [8479, 227, 5413, 8179, 7528]\n",
    "\n",
    "# list to collect results avg over task\n",
    "avg_results = {\n",
    "        \"Delta-AUC-PR\": [],\n",
    "        \"ROC-AUC\": []\n",
    "    }\n",
    "\n",
    "# list to collect results per task\n",
    "all_results = {\n",
    "        \"Delta-AUC-PR\": [],\n",
    "        \"ROC-AUC\": []\n",
    "    }  \n",
    "\n",
    "# train and evaluate model 5 times\n",
    "for run in range(5):\n",
    "    # set seed\n",
    "    seed_value = seeds[run]\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "\n",
    "    # initialize\n",
    "    # writer = SummaryWriter(f\"manual_runs/run_36_upsampling\") # tensorboard\n",
    "    writer = None\n",
    "    model = NeuralNetwork(input_size, hidden_sizes, output_size, dropout_rates)\n",
    "    criterion = compute_weighted_loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # train model\n",
    "    train_loader, val_loader, test_loader = get_datasets(X_train, y_train, X_val, y_val, X_test, y_test, seed_value)\n",
    "    val_loss, val_delta_auc_pr, val_roc_auc, val_pr_auc_per_task, val_roc_auc_per_task = train_model(model, train_loader, test_loader, criterion, optimizer, device, writer, num_epochs=20)\n",
    "    \n",
    "    # collect results\n",
    "    avg_results[\"Delta-AUC-PR\"].append(val_delta_auc_pr)\n",
    "    avg_results[\"ROC-AUC\"].append(val_roc_auc)\n",
    "\n",
    "    all_results[\"Delta-AUC-PR\"].append(np.array(val_pr_auc_per_task))\n",
    "    all_results[\"ROC-AUC\"].append(np.array(val_roc_auc_per_task))\n",
    "    \n",
    "    # ------- for hyperparameter tuning ------- #\n",
    "    # val_loss, val_delta_auc_pr, val_roc_auc = train_model(model, train_loader, val_loader, criterion, optimizer, device, writer, num_epochs=20)\n",
    "\n",
    "    # hparams = {\n",
    "    #     \"lr\": lr,\n",
    "    #     \"batch_size\": batch_size,\n",
    "    #     \"optimizer\": \"Adam\",\n",
    "    #     \"hidden_sizes_1\": hidden_sizes[0],\n",
    "    #     \"hidden_sizes_2\": hidden_sizes[1]\n",
    "    # }\n",
    "    # metrics = {\n",
    "    #     \"auc-pr\": val_delta_auc_pr,\n",
    "    #     \"loss\": val_loss\n",
    "    # }\n",
    "    # writer.add_hparams(hparams, metrics)\n",
    "    # writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute avg and sd over five runs\n",
    "final_auc_pr = np.mean(np.array(avg_results[\"Delta-AUC-PR\"]))\n",
    "final_roc_auc = np.mean(np.array(avg_results[\"ROC-AUC\"]))\n",
    "final_sd_auc_pr = np.std(np.array(avg_results[\"Delta-AUC-PR\"]))\n",
    "final_sd_roc_auc = np.std(np.array(avg_results[\"ROC-AUC\"]))\n",
    "\n",
    "# save in json convertible format\n",
    "final_results = [{\n",
    "    \"Delta-AUC-PR\": float(final_auc_pr),\n",
    "    \"ROC-AUC\": float(final_roc_auc),\n",
    "    \"Sd-Delta-AUC-PR\": float(final_sd_auc_pr),\n",
    "    \"Sd-ROC-AUC\": float(final_sd_roc_auc)\n",
    "}]\n",
    "final_results\n",
    "\n",
    "# save to json file\n",
    "with open(\"./metrics/metrics_pretraining.json\", \"w\") as f:\n",
    "    json.dump(final_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type float32 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# write to json file\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./metrics/metrics_pretraining_per_task.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_results_per_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\json\\__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[0;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[0;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[0;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\json\\encoder.py:430\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m _floatstr(o)\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m--> 430\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\json\\encoder.py:326\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[1;34m(lst, _current_indent_level)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 326\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    328\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\json\\encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\json\\encoder.py:326\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[1;34m(lst, _current_indent_level)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 326\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    328\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\json\\encoder.py:439\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    438\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[1;32m--> 439\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\json\\encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[0;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type float32 is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# calculate mean and sd for five runs but don't average over tasks\n",
    "avg_auc_pr_per_run = np.mean(np.array(all_results[\"Delta-AUC-PR\"]), axis=0)\n",
    "sd_auc_pr_per_run = np.std(np.array(all_results[\"Delta-AUC-PR\"]), axis=0)\n",
    "\n",
    "avg_roc_auc_per_run = np.mean(np.array(all_results[\"ROC-AUC\"]), axis=0)\n",
    "sd_roc_auc_per_run = np.std(np.array(all_results[\"ROC-AUC\"]), axis=0)\n",
    "\n",
    "# save in json convertible format\n",
    "final_results_per_task = [{\n",
    "    \"Delta-AUC-PR per task\": list(avg_auc_pr_per_run),\n",
    "    \"ROC-AUC per task\": list(avg_roc_auc_per_run),\n",
    "    \"Sd-Delta-AUC-PR per task\": list(sd_auc_pr_per_run),\n",
    "    \"Sd-ROC-AUC per task\": list(sd_roc_auc_per_run)\n",
    "}]\n",
    "final_results_per_task\n",
    "\n",
    "# write to json file\n",
    "with open(\"./metrics/metrics_pretraining_per_task.json\", \"w\") as f:\n",
    "    json.dump(final_results_per_task, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type float32 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# write to json file\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./metrics/metrics_pretraining_per_run.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_results_per_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\json\\__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[0;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[0;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[0;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\json\\encoder.py:430\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m _floatstr(o)\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m--> 430\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\json\\encoder.py:326\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[1;34m(lst, _current_indent_level)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 326\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    328\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\json\\encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\json\\encoder.py:326\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[1;34m(lst, _current_indent_level)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 326\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    328\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\json\\encoder.py:439\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    438\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[1;32m--> 439\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\json\\encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[0;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type float32 is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# calculate mean and sd for five runs but do average over tasks\n",
    "avg_auc_pr_per_task = np.mean(np.array(all_results[\"Delta-AUC-PR\"]), axis=1)\n",
    "sd_auc_pr_per_task = np.std(np.array(all_results[\"Delta-AUC-PR\"]), axis=1)\n",
    "\n",
    "avg_roc_auc_per_task = np.mean(np.array(all_results[\"ROC-AUC\"]), axis=1)\n",
    "sd_roc_auc_per_task = np.std(np.array(all_results[\"ROC-AUC\"]), axis=1)\n",
    "\n",
    "# save in json convertible format\n",
    "final_results_per_task = [{\n",
    "    \"Delta-AUC-PR per run\": list(avg_auc_pr_per_task),\n",
    "    \"ROC-AUC per run\": list(avg_roc_auc_per_task),\n",
    "    \"Sd-Delta-AUC-PR per run\": list(sd_auc_pr_per_task),\n",
    "    \"Sd-ROC-AUC per run\": list(sd_roc_auc_per_task)\n",
    "}]\n",
    "final_results_per_task\n",
    "\n",
    "# write to json file\n",
    "with open(\"./metrics/metrics_pretraining_per_run.json\", \"w\") as f:\n",
    "    json.dump(final_results_per_task, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
